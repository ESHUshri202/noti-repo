{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOO8vvZvwnh0ajG3CJWoIiE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ESHUshri202/noti-repo/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj-_oG2XSg_2",
        "outputId": "db595ddc-6ee2-4ba6-a334-f40b1aa79ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans\n",
            "  Downloading googletrans-4.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.13.2)\n",
            "Downloading googletrans-4.0.2-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: googletrans\n",
            "Successfully installed googletrans-4.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install googletrans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "Trans = Translator()"
      ],
      "metadata": {
        "id": "uakpLwkLSsjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"hola\"\n",
        "\n",
        "Output = Trans.Translator(txt, dest= \"en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "KKlNZJ30S62b",
        "outputId": "a06df1c1-4f4c-4bcb-8f57-3b17d344a411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Translator' object has no attribute 'Translator'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8d56b9d912e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hola\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Translator' object has no attribute 'Translator'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "from googletrans import Translator\n",
        "\n",
        "# Allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def main():\n",
        "    translator = Translator()\n",
        "    txt = input()\n",
        "    output = await translator.translate(txt, dest='en')\n",
        "    print(output.text)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2AjTFkFTWsz",
        "outputId": "6a500920-fc71-4b7a-bb41-d4ae7f6f41dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mushi mushi\n",
            "Ignore Ignore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def generate_ludo_notification(max_length=40):\n",
        "    # Load model and tokenizer\n",
        "    model_name = 'gpt2'\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    # Choose a themed prompt\n",
        "    prompt = random.choice([\n",
        "        \"Queen Ludo misses you: \",\n",
        "        \"Ludo Notification: \",\n",
        "        \"Game Update: \",\n",
        "        \"Your Queen says: \",\n",
        "        \"Offline Alert: \"\n",
        "    ])\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate text with sampling for creativity\n",
        "    output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=max_length,\n",
        "    num_return_sequences=3,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=0.9,\n",
        "    no_repeat_ngram_size=2,\n",
        "    pad_token_id=tokenizer.eos_token_id  # âœ… Fixes warning\n",
        ")\n",
        "\n",
        "\n",
        "    # Decode outputs\n",
        "    messages = []\n",
        "    for i in range(3):\n",
        "        text = tokenizer.decode(output[i], skip_special_tokens=True)\n",
        "        # Keep only the part after the prompt\n",
        "        message = text.replace(prompt, \"\").strip()\n",
        "        messages.append(message)\n",
        "\n",
        "    return messages\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating fun Queen Ludo offline notifications...\\n\")\n",
        "    for msg in generate_ludo_notification():\n",
        "        print(\"ğŸ””\", msg)\n"
      ],
      "metadata": {
        "id": "V3WihRVm1oef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aea47c8-aae3-4841-9026-15cff4a0ec38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating fun Queen Ludo offline notifications...\n",
            "\n",
            "ğŸ”” \"Yes, sir.\"\n",
            "He looks down at his hands. He says, \"I'm glad you're here. I've had too many bad memories. It's\n",
            "ğŸ”” \"You have some kind of idea of what you want to do with your time. What would you like to build?\" And as she says this, she gets to her\n",
            "ğŸ”” ã€I would be able to do so much more if you could marry.ã€.\n",
            "\n",
            "Hinata nods. The Princess can't stop her. She has no choice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import random\n",
        "import re\n",
        "\n",
        "def generate_ludo_notification(max_length=40):\n",
        "    # Load model and tokenizer\n",
        "    model_name = 'gpt2'\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    # Choose a stylized prompt\n",
        "    prompt = random.choice([\n",
        "        \"Queen Ludo Notification: \",\n",
        "        \"Welcome back to Queen Ludo! \",\n",
        "        \"Ludo Alert: \",\n",
        "        \"Game Tip: \",\n",
        "        \"Offline Message: \",\n",
        "        \"Daily Bonus Notification: \",\n",
        "    ])\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate creative text\n",
        "    output = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=30,  # controls length better\n",
        "    num_return_sequences=3,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=0.9,\n",
        "    no_repeat_ngram_size=2,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "\n",
        "    # Clean and truncate outputs\n",
        "    messages = []\n",
        "    for i in range(3):\n",
        "        full_text = tokenizer.decode(output[i], skip_special_tokens=True)\n",
        "        message = full_text.replace(prompt, \"\").strip()\n",
        "\n",
        "        # Truncate at the first sentence-ending punctuation\n",
        "        message = re.split(r'[.!\\n]', message)[0].strip()\n",
        "        message = message[:100]  # limit to 100 chars just in case\n",
        "\n",
        "        # Final formatting\n",
        "        messages.append(f\"ğŸ”” {message}.\")\n",
        "\n",
        "    return messages\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating fun Queen Ludo offline notifications...\\n\")\n",
        "    for msg in generate_ludo_notification():\n",
        "        print(msg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zarItSC97we",
        "outputId": "fb631e7e-644d-4e62-d265-f3a9b1c4ce68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating fun Queen Ludo offline notifications...\n",
            "\n",
            "ğŸ”” This post may contain affiliate links, which means I earn a small commission if you make a purchase .\n",
            "ğŸ”” This week we have a new episode of Krusty the Clown.\n",
            "ğŸ”” After her last year, she was able to make her way back home to the mainland, where she met a few fri.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import re\n",
        "\n",
        "def generate_ludo_notification():\n",
        "    model_name = 'gpt2'\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    prompt = \"\"\"Generate fun and engaging Queen Ludo notifications for players:\n",
        "\n",
        "1. ğŸ”” Welcome back, Queen! Your throne is waiting on the board.\n",
        "2. ğŸ”” Daily Bonus unlocked! Roll the dice and claim your reward.\n",
        "3. ğŸ”” Your pawns miss you! Make your move and dominate the game.\n",
        "4. ğŸ”” The dice are ready â€” come and conquer your kingdom!\n",
        "5. ğŸ”” Opponents are making moves while youâ€™re away. Hurry back!\n",
        "6. ğŸ”” Your Queen awaits to lead you to victory.\n",
        "7. ğŸ”” Spin the dice and bring glory to your realm!\n",
        "8. ğŸ””\"\"\"\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=40,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.9,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    generated = decoded.split(\"\\n\")\n",
        "\n",
        "    # Extract lines starting with a number + dot + bell emoji\n",
        "    notifications = [line.strip() for line in generated if re.match(r\"\\d+\\.\\sğŸ””\", line.strip())]\n",
        "\n",
        "    return notifications\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating Queen Ludo notifications...\\n\")\n",
        "    for msg in generate_ludo_notification():\n",
        "        print(msg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gx9Wz6AAjjL",
        "outputId": "26ebf824-38b5-4315-9fbc-c0e1598417b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Queen Ludo notifications...\n",
            "\n",
            "1. ğŸ”” Welcome back, Queen! Your throne is waiting on the board.\n",
            "2. ğŸ”” Daily Bonus unlocked! Roll the dice and claim your reward.\n",
            "3. ğŸ”” Your pawns miss you! Make your move and dominate the game.\n",
            "4. ğŸ”” The dice are ready â€” come and conquer your kingdom!\n",
            "5. ğŸ”” Opponents are making moves while youâ€™re away. Hurry back!\n",
            "6. ğŸ”” Your Queen awaits to lead you to victory.\n",
            "7. ğŸ”” Spin the dice and bring glory to your realm!\n",
            "8. ğŸ”” A triumphant win or lose? Just wait until your Queen reaches her final showdown.\n",
            "9. ğŸ”” You have a queen! Choose your strategy wisely â€” choose wisely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import re\n",
        "\n",
        "def generate_ludo_notification():\n",
        "    model_name = 'gpt2'\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    prompt = \"\"\"Generate Queen Ludo notifications for players based on login frequency:\n",
        "\n",
        "Login once a week:\n",
        "1. ğŸ”” Welcome back, Queen! Your throne is ready for you this week.\n",
        "2. ğŸ”” Youâ€™ve kept the game alive! Roll the dice and conquer.\n",
        "3. ğŸ”” Weekly bonus unlocked! Use it to rule the board.\n",
        "\n",
        "Login once a month:\n",
        "4. ğŸ”” Itâ€™s been a month, Queen! The board missed your royal moves.\n",
        "5. ğŸ”” Monthly reward waiting! Spin and claim your crown.\n",
        "6. ğŸ”” Your pawns are getting restless. Time to play and win!\n",
        "\n",
        "Not logged in for a long time:\n",
        "7. ğŸ”” The kingdomâ€™s waiting! Your Queenâ€™s throne is empty.\n",
        "8. ğŸ”” Long time no see! Your rivals are gaining ground.\n",
        "9. ğŸ”” Return now and reclaim your crown before itâ€™s too late.\n",
        "10. ğŸ””\"\"\"\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.9,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    generated = decoded.split(\"\\n\")\n",
        "\n",
        "    notifications = [line.strip() for line in generated if re.match(r\"\\d+\\.\\sğŸ””\", line.strip())]\n",
        "\n",
        "    return notifications\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating Queen Ludo notifications based on login frequency...\\n\")\n",
        "    for msg in generate_ludo_notification():\n",
        "        print(msg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsyGIdlABypw",
        "outputId": "15bb6dac-7944-4f15-9841-ef4da016eb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Queen Ludo notifications based on login frequency...\n",
            "\n",
            "1. ğŸ”” Welcome back, Queen! Your throne is ready for you this week.\n",
            "2. ğŸ”” Youâ€™ve kept the game alive! Roll the dice and conquer.\n",
            "3. ğŸ”” Weekly bonus unlocked! Use it to rule the board.\n",
            "4. ğŸ”” Itâ€™s been a month, Queen! The board missed your royal moves.\n",
            "5. ğŸ”” Monthly reward waiting! Spin and claim your crown.\n",
            "6. ğŸ”” Your pawns are getting restless. Time to play and win!\n",
            "7. ğŸ”” The kingdomâ€™s waiting! Your Queenâ€™s throne is empty.\n",
            "8. ğŸ”” Long time no see! Your rivals are gaining ground.\n",
            "9. ğŸ”” Return now and reclaim your crown before itâ€™s too late.\n",
            "10. ğŸ”” Give your queen a royal smile this week.\n",
            "11. ğŸ”” The king's gone to hell...\n",
            "12. ğŸ”” What happened to your queen's memories?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mcWSjscdCmuo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}