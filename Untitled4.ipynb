{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOO8vvZvwnh0ajG3CJWoIiE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ESHUshri202/noti-repo/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj-_oG2XSg_2",
        "outputId": "db595ddc-6ee2-4ba6-a334-f40b1aa79ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans\n",
            "  Downloading googletrans-4.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.14.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.13.2)\n",
            "Downloading googletrans-4.0.2-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: googletrans\n",
            "Successfully installed googletrans-4.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install googletrans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from googletrans import Translator\n",
        "\n",
        "Trans = Translator()"
      ],
      "metadata": {
        "id": "uakpLwkLSsjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"hola\"\n",
        "\n",
        "Output = Trans.Translator(txt, dest= \"en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "KKlNZJ30S62b",
        "outputId": "a06df1c1-4f4c-4bcb-8f57-3b17d344a411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Translator' object has no attribute 'Translator'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8d56b9d912e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hola\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Translator' object has no attribute 'Translator'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "from googletrans import Translator\n",
        "\n",
        "# Allow nested event loops\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def main():\n",
        "    translator = Translator()\n",
        "    txt = input()\n",
        "    output = await translator.translate(txt, dest='en')\n",
        "    print(output.text)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2AjTFkFTWsz",
        "outputId": "6a500920-fc71-4b7a-bb41-d4ae7f6f41dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mushi mushi\n",
            "Ignore Ignore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def generate_ludo_notification(max_length=40):\n",
        "    # Load model and tokenizer\n",
        "    model_name = 'gpt2'\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    # Choose a themed prompt\n",
        "    prompt = random.choice([\n",
        "        \"Queen Ludo misses you: \",\n",
        "        \"Ludo Notification: \",\n",
        "        \"Game Update: \",\n",
        "        \"Your Queen says: \",\n",
        "        \"Offline Alert: \"\n",
        "    ])\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate text with sampling for creativity\n",
        "    output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=max_length,\n",
        "    num_return_sequences=3,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=0.9,\n",
        "    no_repeat_ngram_size=2,\n",
        "    pad_token_id=tokenizer.eos_token_id  # ‚úÖ Fixes warning\n",
        ")\n",
        "\n",
        "\n",
        "    # Decode outputs\n",
        "    messages = []\n",
        "    for i in range(3):\n",
        "        text = tokenizer.decode(output[i], skip_special_tokens=True)\n",
        "        # Keep only the part after the prompt\n",
        "        message = text.replace(prompt, \"\").strip()\n",
        "        messages.append(message)\n",
        "\n",
        "    return messages\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating fun Queen Ludo offline notifications...\\n\")\n",
        "    for msg in generate_ludo_notification():\n",
        "        print(\"üîî\", msg)\n"
      ],
      "metadata": {
        "id": "V3WihRVm1oef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aea47c8-aae3-4841-9026-15cff4a0ec38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating fun Queen Ludo offline notifications...\n",
            "\n",
            "üîî \"Yes, sir.\"\n",
            "He looks down at his hands. He says, \"I'm glad you're here. I've had too many bad memories. It's\n",
            "üîî \"You have some kind of idea of what you want to do with your time. What would you like to build?\" And as she says this, she gets to her\n",
            "üîî „ÄéI would be able to do so much more if you could marry.„Äè.\n",
            "\n",
            "Hinata nods. The Princess can't stop her. She has no choice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import random\n",
        "import re\n",
        "\n",
        "def generate_ludo_notification(max_length=40):\n",
        "    # Load model and tokenizer\n",
        "    model_name = 'gpt2'\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    # Choose a stylized prompt\n",
        "    prompt = random.choice([\n",
        "        \"Queen Ludo Notification: \",\n",
        "        \"Welcome back to Queen Ludo! \",\n",
        "        \"Ludo Alert: \",\n",
        "        \"Game Tip: \",\n",
        "        \"Offline Message: \",\n",
        "        \"Daily Bonus Notification: \",\n",
        "    ])\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    # Generate creative text\n",
        "    output = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=30,  # controls length better\n",
        "    num_return_sequences=3,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    temperature=0.9,\n",
        "    no_repeat_ngram_size=2,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "\n",
        "    # Clean and truncate outputs\n",
        "    messages = []\n",
        "    for i in range(3):\n",
        "        full_text = tokenizer.decode(output[i], skip_special_tokens=True)\n",
        "        message = full_text.replace(prompt, \"\").strip()\n",
        "\n",
        "        # Truncate at the first sentence-ending punctuation\n",
        "        message = re.split(r'[.!\\n]', message)[0].strip()\n",
        "        message = message[:100]  # limit to 100 chars just in case\n",
        "\n",
        "        # Final formatting\n",
        "        messages.append(f\"üîî {message}.\")\n",
        "\n",
        "    return messages\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating fun Queen Ludo offline notifications...\\n\")\n",
        "    for msg in generate_ludo_notification():\n",
        "        print(msg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zarItSC97we",
        "outputId": "fb631e7e-644d-4e62-d265-f3a9b1c4ce68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating fun Queen Ludo offline notifications...\n",
            "\n",
            "üîî This post may contain affiliate links, which means I earn a small commission if you make a purchase .\n",
            "üîî This week we have a new episode of Krusty the Clown.\n",
            "üîî After her last year, she was able to make her way back home to the mainland, where she met a few fri.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import re\n",
        "\n",
        "def generate_ludo_notification():\n",
        "    model_name = 'gpt2'\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    prompt = \"\"\"Generate fun and engaging Queen Ludo notifications for players:\n",
        "\n",
        "1. üîî Welcome back, Queen! Your throne is waiting on the board.\n",
        "2. üîî Daily Bonus unlocked! Roll the dice and claim your reward.\n",
        "3. üîî Your pawns miss you! Make your move and dominate the game.\n",
        "4. üîî The dice are ready ‚Äî come and conquer your kingdom!\n",
        "5. üîî Opponents are making moves while you‚Äôre away. Hurry back!\n",
        "6. üîî Your Queen awaits to lead you to victory.\n",
        "7. üîî Spin the dice and bring glory to your realm!\n",
        "8. üîî\"\"\"\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=40,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.9,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    generated = decoded.split(\"\\n\")\n",
        "\n",
        "    # Extract lines starting with a number + dot + bell emoji\n",
        "    notifications = [line.strip() for line in generated if re.match(r\"\\d+\\.\\süîî\", line.strip())]\n",
        "\n",
        "    return notifications\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating Queen Ludo notifications...\\n\")\n",
        "    for msg in generate_ludo_notification():\n",
        "        print(msg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gx9Wz6AAjjL",
        "outputId": "26ebf824-38b5-4315-9fbc-c0e1598417b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Queen Ludo notifications...\n",
            "\n",
            "1. üîî Welcome back, Queen! Your throne is waiting on the board.\n",
            "2. üîî Daily Bonus unlocked! Roll the dice and claim your reward.\n",
            "3. üîî Your pawns miss you! Make your move and dominate the game.\n",
            "4. üîî The dice are ready ‚Äî come and conquer your kingdom!\n",
            "5. üîî Opponents are making moves while you‚Äôre away. Hurry back!\n",
            "6. üîî Your Queen awaits to lead you to victory.\n",
            "7. üîî Spin the dice and bring glory to your realm!\n",
            "8. üîî A triumphant win or lose? Just wait until your Queen reaches her final showdown.\n",
            "9. üîî You have a queen! Choose your strategy wisely ‚Äî choose wisely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "import re\n",
        "\n",
        "def generate_ludo_notification():\n",
        "    model_name = 'gpt2'\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    prompt = \"\"\"Generate Queen Ludo notifications for players based on login frequency:\n",
        "\n",
        "Login once a week:\n",
        "1. üîî Welcome back, Queen! Your throne is ready for you this week.\n",
        "2. üîî You‚Äôve kept the game alive! Roll the dice and conquer.\n",
        "3. üîî Weekly bonus unlocked! Use it to rule the board.\n",
        "\n",
        "Login once a month:\n",
        "4. üîî It‚Äôs been a month, Queen! The board missed your royal moves.\n",
        "5. üîî Monthly reward waiting! Spin and claim your crown.\n",
        "6. üîî Your pawns are getting restless. Time to play and win!\n",
        "\n",
        "Not logged in for a long time:\n",
        "7. üîî The kingdom‚Äôs waiting! Your Queen‚Äôs throne is empty.\n",
        "8. üîî Long time no see! Your rivals are gaining ground.\n",
        "9. üîî Return now and reclaim your crown before it‚Äôs too late.\n",
        "10. üîî\"\"\"\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=50,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.9,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    generated = decoded.split(\"\\n\")\n",
        "\n",
        "    notifications = [line.strip() for line in generated if re.match(r\"\\d+\\.\\süîî\", line.strip())]\n",
        "\n",
        "    return notifications\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating Queen Ludo notifications based on login frequency...\\n\")\n",
        "    for msg in generate_ludo_notification():\n",
        "        print(msg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsyGIdlABypw",
        "outputId": "15bb6dac-7944-4f15-9841-ef4da016eb27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Queen Ludo notifications based on login frequency...\n",
            "\n",
            "1. üîî Welcome back, Queen! Your throne is ready for you this week.\n",
            "2. üîî You‚Äôve kept the game alive! Roll the dice and conquer.\n",
            "3. üîî Weekly bonus unlocked! Use it to rule the board.\n",
            "4. üîî It‚Äôs been a month, Queen! The board missed your royal moves.\n",
            "5. üîî Monthly reward waiting! Spin and claim your crown.\n",
            "6. üîî Your pawns are getting restless. Time to play and win!\n",
            "7. üîî The kingdom‚Äôs waiting! Your Queen‚Äôs throne is empty.\n",
            "8. üîî Long time no see! Your rivals are gaining ground.\n",
            "9. üîî Return now and reclaim your crown before it‚Äôs too late.\n",
            "10. üîî Give your queen a royal smile this week.\n",
            "11. üîî The king's gone to hell...\n",
            "12. üîî What happened to your queen's memories?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mcWSjscdCmuo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}